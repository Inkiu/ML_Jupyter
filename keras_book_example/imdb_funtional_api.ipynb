{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "dimension = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=dimension)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_train = vectorize_sequences(x_train, dimension)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "x_test = vectorize_sequences(x_test, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000) (25000,)\n",
      "25000 25000\n",
      "[0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(len(x_train), len(x_test))\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_model = Sequential()\n",
    "sequence_model.add(Dense(16, activation = 'relu', input_shape = (x_train.shape[-1],)))\n",
    "sequence_model.add(Dropout(0.5))\n",
    "sequence_model.add(Dense(16, activation = 'relu'))\n",
    "sequence_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "sequence_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape = (x_train.shape[-1],))\n",
    "x = Dense(16, activation = 'relu')(input_tensor)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(16, activation = 'relu')(x)\n",
    "output_tensor = Dense(1, activation = 'sigmoid')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.5672 - acc: 0.7069 - val_loss: 0.3920 - val_acc: 0.8336\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.3703 - acc: 0.8457 - val_loss: 0.3551 - val_acc: 0.8414\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.2896 - acc: 0.8857 - val_loss: 0.3623 - val_acc: 0.8344\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.2373 - acc: 0.9062 - val_loss: 0.4007 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.2044 - acc: 0.9224 - val_loss: 0.4260 - val_acc: 0.8300\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1751 - acc: 0.9321 - val_loss: 0.4627 - val_acc: 0.8288\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1492 - acc: 0.9435 - val_loss: 0.5096 - val_acc: 0.8296\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1362 - acc: 0.9471 - val_loss: 0.5294 - val_acc: 0.8284\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1221 - acc: 0.9506 - val_loss: 0.5642 - val_acc: 0.8238\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1098 - acc: 0.9541 - val_loss: 0.6110 - val_acc: 0.8258\n"
     ]
    }
   ],
   "source": [
    "sequence_history = sequence_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 128,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.5609 - acc: 0.7142 - val_loss: 0.3934 - val_acc: 0.8322\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.3689 - acc: 0.8461 - val_loss: 0.3623 - val_acc: 0.8334\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.2915 - acc: 0.8860 - val_loss: 0.3743 - val_acc: 0.8384\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.2435 - acc: 0.9056 - val_loss: 0.3995 - val_acc: 0.8350\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.2030 - acc: 0.9221 - val_loss: 0.4178 - val_acc: 0.8334\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1761 - acc: 0.9329 - val_loss: 0.4811 - val_acc: 0.8320\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1512 - acc: 0.9420 - val_loss: 0.5072 - val_acc: 0.8278\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.1360 - acc: 0.9484 - val_loss: 0.5561 - val_acc: 0.8268\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.1174 - acc: 0.9535 - val_loss: 0.5900 - val_acc: 0.8220\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.1067 - acc: 0.9576 - val_loss: 0.6420 - val_acc: 0.8240\n"
     ]
    }
   ],
   "source": [
    "api_history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 128,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 153us/step\n",
      "[0.6098022779655456, 0.82212]\n",
      "25000/25000 [==============================] - 3s 133us/step\n",
      "[0.647737896361351, 0.82144]\n"
     ]
    }
   ],
   "source": [
    "print(sequence_model.evaluate(x_test, y_test))\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_voca_size = 10000\n",
    "question_voca_size = 10000\n",
    "answer_voca_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "refer (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      refer[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           8320        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 500)          32500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,013,236\n",
      "Trainable params: 1,013,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM\n",
    "from keras import layers\n",
    "\n",
    "refer_input = Input(shape = (None,), dtype='int32', name = 'refer')\n",
    "embedded_refer = Embedding(reference_voca_size, 64)(refer_input)\n",
    "encoded_refer = LSTM(32)(embedded_refer)\n",
    "\n",
    "q_input = Input(shape = (None,), dtype = 'int32', name = 'question')\n",
    "embedded_q = Embedding(reference_voca_size, 32)(q_input)\n",
    "encoded_q = LSTM(32)(embedded_q)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_refer, encoded_q], axis = -1)\n",
    "\n",
    "answer = Dense(answer_voca_size, activation = 'softmax')(concatenated)\n",
    "\n",
    "model = Model([refer_input, q_input], answer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100) (1000, 100) (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "refer = np.random.randint(1, reference_voca_size, size = (num_samples, max_len))\n",
    "question = np.random.randint(1, question_voca_size, size = (num_samples, max_len))\n",
    "answer = np.random.randint(0, answer_voca_size, size = (num_samples,))\n",
    "answer = to_categorical(answer)\n",
    "\n",
    "print(refer.shape, question.shape, answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 6.2138 - acc: 0.0025 - val_loss: 6.2152 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 6.1941 - acc: 0.0537 - val_loss: 6.2164 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 6.1001 - acc: 0.0088 - val_loss: 6.3098 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.9657 - acc: 0.0112 - val_loss: 6.3836 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.8977 - acc: 0.0112 - val_loss: 6.5039 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.8458 - acc: 0.0112 - val_loss: 6.3831 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.7779 - acc: 0.0112 - val_loss: 6.5946 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.7029 - acc: 0.0112 - val_loss: 6.3948 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.6549 - acc: 0.0112 - val_loss: 6.6545 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 5.5786 - acc: 0.0112 - val_loss: 6.4388 - val_acc: 0.0050\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'rmsprop',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "history = model.fit(\n",
    "    {'refer': refer, 'question': question}, answer,\n",
    "    epochs = 10,\n",
    "    batch_size = 128,\n",
    "    validation_split = 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_size = 50000\n",
    "num_income_grous = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_input = Input(shape=(None,), dtype='int32', name='post')\n",
    "embedded_input = Embedding(voca_size, 256)(post_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_input)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(embedded_input)\n",
    "x = Conv1D(256, 5, activation='relu')(embedded_input)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(embedded_input)\n",
    "x = Conv1D(256, 5, activation='relu')(embedded_input)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(128, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_prediction = Dense(1, name='age')(x)\n",
    "income_prediction = Dense(num_income_grous, name='income')(x)\n",
    "gender_predection = Dense(1, name='gender')(x)\n",
    "\n",
    "model = Model(\n",
    "    post_input,\n",
    "    [age_prediction, income_prediction, gender_predection]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = {\n",
    "        'age': 'mse',\n",
    "        'income': 'categorical_crossentropy',\n",
    "        'gender': 'binary_crossentropy'\n",
    "    },\n",
    "    loss_weights = {\n",
    "        'age': 0.25,\n",
    "        'income': 1.,\n",
    "        'gender': 10.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100) (1000,) (1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "post = np.random.randint(1, voca_size, size = (num_samples, max_len))\n",
    "\n",
    "y_age = np.random.randint(0, 100, size = (num_samples,))\n",
    "\n",
    "y_income = np.random.randint(0, num_income_grous, size = (num_samples,))\n",
    "y_income = to_categorical(y_income)\n",
    "\n",
    "y_gender = np.random.randint(0, 2, size = (num_samples))\n",
    "\n",
    "print(refer.shape, y_age.shape, y_income.shape, y_gender.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 872.6799 - age_loss: 3413.2521 - income_loss: 7.4813 - gender_loss: 1.1886 - val_loss: 796.3908 - val_age_loss: 3112.3593 - val_income_loss: 11.0867 - val_gender_loss: 0.7214\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 234us/step - loss: 850.1307 - age_loss: 3343.3682 - income_loss: 10.1066 - gender_loss: 0.4182 - val_loss: 779.7531 - val_age_loss: 3057.2733 - val_income_loss: 8.2912 - val_gender_loss: 0.7144\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 231us/step - loss: 818.6964 - age_loss: 3231.0413 - income_loss: 8.3685 - gender_loss: 0.2568 - val_loss: 758.4823 - val_age_loss: 2973.1486 - val_income_loss: 7.7433 - val_gender_loss: 0.7452\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 229us/step - loss: 771.1454 - age_loss: 3046.4989 - income_loss: 7.9273 - gender_loss: 0.1593 - val_loss: 724.6806 - val_age_loss: 2836.6258 - val_income_loss: 7.7487 - val_gender_loss: 0.7776\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 229us/step - loss: 690.5089 - age_loss: 2724.8227 - income_loss: 8.3330 - gender_loss: 0.0970 - val_loss: 669.0911 - val_age_loss: 2614.4769 - val_income_loss: 7.7397 - val_gender_loss: 0.7732\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 231us/step - loss: 561.0772 - age_loss: 2207.1730 - income_loss: 8.6770 - gender_loss: 0.0607 - val_loss: 579.7198 - val_age_loss: 2255.6197 - val_income_loss: 7.7882 - val_gender_loss: 0.8027\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 233us/step - loss: 371.7937 - age_loss: 1448.9959 - income_loss: 9.1222 - gender_loss: 0.0422 - val_loss: 452.1926 - val_age_loss: 1743.7490 - val_income_loss: 8.9455 - val_gender_loss: 0.7310\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 231us/step - loss: 183.6153 - age_loss: 698.4797 - income_loss: 8.2404 - gender_loss: 0.0755 - val_loss: 346.0065 - val_age_loss: 1304.0846 - val_income_loss: 7.3337 - val_gender_loss: 1.2652\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 226us/step - loss: 93.5102 - age_loss: 316.1798 - income_loss: 8.3210 - gender_loss: 0.6144 - val_loss: 375.4445 - val_age_loss: 1153.5252 - val_income_loss: 8.9455 - val_gender_loss: 7.8118\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 231us/step - loss: 72.6998 - age_loss: 171.7535 - income_loss: 9.3888 - gender_loss: 2.0373 - val_loss: 296.6810 - val_age_loss: 1116.2459 - val_income_loss: 9.0261 - val_gender_loss: 0.8593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    post, { 'age': y_age, 'income': y_income, 'gender': y_gender },\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
